{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thaneesan99/Pytorch_Mask_RCNN/blob/main/PytorchMaskRCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c932cffd",
      "metadata": {
        "id": "c932cffd"
      },
      "outputs": [],
      "source": [
        "# Download the dataset zip file\n",
        "!curl -L \"place_your_dataset_link\" -o roboflow.zip\n",
        "\n",
        "# Unzip the dataset into the 'dataset' folder\n",
        "!unzip roboflow.zip -d dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "65099742",
      "metadata": {
        "id": "65099742"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools import mask as coco_mask\n",
        "from torchvision import transforms as T\n",
        "import torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c92f305a",
      "metadata": {
        "id": "c92f305a"
      },
      "outputs": [],
      "source": [
        "class CocoInstanceDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, img_dir, ann_file, transforms=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.coco = COCO(ann_file)\n",
        "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        coco = self.coco\n",
        "        img_id = self.ids[index]\n",
        "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
        "        anns = coco.loadAnns(ann_ids)\n",
        "\n",
        "        path = coco.loadImgs(img_id)[0]['file_name']\n",
        "        img = Image.open(os.path.join(self.img_dir, path)).convert(\"RGB\")\n",
        "\n",
        "        boxes, labels, masks = [], [], []\n",
        "        for ann in anns:\n",
        "            x, y, w, h = ann['bbox']\n",
        "            boxes.append([x, y, x + w, y + h])\n",
        "            labels.append(ann['category_id'])\n",
        "\n",
        "            rle = coco_mask.frPyObjects(ann['segmentation'], img.height, img.width)\n",
        "            m = coco_mask.decode(rle)\n",
        "            if len(m.shape) == 3:\n",
        "                m = np.any(m, axis=2)\n",
        "            masks.append(m)\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        masks = torch.as_tensor(np.array(masks), dtype=torch.uint8)\n",
        "\n",
        "        target = {\n",
        "            \"boxes\": boxes,\n",
        "            \"labels\": labels,\n",
        "            \"masks\": masks,\n",
        "            \"image_id\": torch.tensor([img_id]),\n",
        "        }\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c49ac49c",
      "metadata": {
        "id": "c49ac49c"
      },
      "outputs": [],
      "source": [
        "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "\n",
        "# Define the transform for the dataset\n",
        "def get_transform():\n",
        "    return T.Compose([\n",
        "        T.ToTensor(),  # converts PIL image to [C,H,W] float tensor in [0,1]\n",
        "    ])\n",
        "\n",
        "\n",
        "def get_model_instance_segmentation(num_classes):\n",
        "    model = maskrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "    # Replace box head\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    # Replace mask head\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, 256, num_classes)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "train_dataset = CocoInstanceDataset(\"/content/dataset/train\", \"/content/dataset/train/_annotations.coco.json\", transforms=get_transform())\n",
        "val_dataset = CocoInstanceDataset(\"/content/dataset/valid\", \"/content/dataset/valid/_annotations.coco.json\", transforms=get_transform())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=2, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3142d23",
      "metadata": {
        "id": "a3142d23"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "num_classes = 2  # background + your single object class (update as needed)\n",
        "num_epochs = 10\n",
        "\n",
        "model = get_model_instance_segmentation(num_classes)\n",
        "model.to(device)\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "643c8444",
      "metadata": {
        "id": "643c8444"
      },
      "outputs": [],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, targets in train_loader:\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += losses.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "eb926be2",
      "metadata": {
        "id": "eb926be2"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"maskrcnn_coco_model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('maskrcnn_coco_model.pt')"
      ],
      "metadata": {
        "id": "hOPQH4Pbb_2F"
      },
      "id": "hOPQH4Pbb_2F",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}